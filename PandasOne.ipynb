{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Filter channels that were created before 2010 and have more than 5 billion total views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rank                    Youtuber  subscribers   video views  \\\n",
      "0       1                    T-Series    245000000  2.280000e+11   \n",
      "3       4  Cocomelon - Nursery Rhymes    162000000  1.640000e+11   \n",
      "4       5                   SET India    159000000  1.480000e+11   \n",
      "11     12                         WWE     96000000  7.742847e+10   \n",
      "14     15                   Goldmines     86900000  2.411823e+10   \n",
      "..    ...                         ...          ...           ...   \n",
      "961   962           elcarteldesantatv     12500000  7.489455e+09   \n",
      "963   964                   Zee Tamil     12500000  1.155219e+10   \n",
      "982   983             DisneyChannelUK     12400000  1.260749e+10   \n",
      "986   987                   ANNA KOVA     12400000  1.395959e+10   \n",
      "987   988               Avril Lavigne     12400000  6.202090e+09   \n",
      "\n",
      "             category                       Title  uploads         Country  \\\n",
      "0               Music                    T-Series    20082           India   \n",
      "3           Education  Cocomelon - Nursery Rhymes      966   United States   \n",
      "4               Shows                   SET India   116536           India   \n",
      "11             Sports                         WWE    70127   United States   \n",
      "14   Film & Animation                   goldmines        1             NaN   \n",
      "..                ...                         ...      ...             ...   \n",
      "961             Music           elcarteldesantatv      377          Mexico   \n",
      "963     Entertainment                   Zee Tamil   102699           India   \n",
      "982             Music             DisneyChannelUK     4422  United Kingdom   \n",
      "986    People & Blogs                    annakova        1             NaN   \n",
      "987             Music               Avril Lavigne      205   United States   \n",
      "\n",
      "    Abbreviation   channel_type  ...  subscribers_for_last_30_days  \\\n",
      "0             IN          Music  ...                     2000000.0   \n",
      "3             US      Education  ...                     1000000.0   \n",
      "4             IN  Entertainment  ...                     1000000.0   \n",
      "11            US         Sports  ...                      600000.0   \n",
      "14           NaN          Music  ...                           NaN   \n",
      "..           ...            ...  ...                           ...   \n",
      "961           MX  Entertainment  ...                      100000.0   \n",
      "963           IN  Entertainment  ...                      200000.0   \n",
      "982           GB  Entertainment  ...                           NaN   \n",
      "986          NaN           Film  ...                           NaN   \n",
      "987           US          Music  ...                           NaN   \n",
      "\n",
      "     created_year  created_month  created_date  \\\n",
      "0          2006.0            Mar          13.0   \n",
      "3          2006.0            Sep           1.0   \n",
      "4          2006.0            Sep          20.0   \n",
      "11         2007.0            May          11.0   \n",
      "14         2006.0            Aug          15.0   \n",
      "..            ...            ...           ...   \n",
      "961        2008.0            Nov          27.0   \n",
      "963        2008.0            Aug          26.0   \n",
      "982        2007.0            Dec           6.0   \n",
      "986        2006.0            Jun          18.0   \n",
      "987        2005.0            Oct           8.0   \n",
      "\n",
      "     Gross tertiary education enrollment (%)    Population  Unemployment rate  \\\n",
      "0                                       28.1  1.366418e+09               5.36   \n",
      "3                                       88.2  3.282395e+08              14.70   \n",
      "4                                       28.1  1.366418e+09               5.36   \n",
      "11                                      88.2  3.282395e+08              14.70   \n",
      "14                                       NaN           NaN                NaN   \n",
      "..                                       ...           ...                ...   \n",
      "961                                     40.2  1.260140e+08               3.42   \n",
      "963                                     28.1  1.366418e+09               5.36   \n",
      "982                                     60.0  6.683440e+07               3.85   \n",
      "986                                      NaN           NaN                NaN   \n",
      "987                                     88.2  3.282395e+08              14.70   \n",
      "\n",
      "     Urban_population   Latitude   Longitude  \n",
      "0         471031528.0  20.593684   78.962880  \n",
      "3         270663028.0  37.090240  -95.712891  \n",
      "4         471031528.0  20.593684   78.962880  \n",
      "11        270663028.0  37.090240  -95.712891  \n",
      "14                NaN        NaN         NaN  \n",
      "..                ...        ...         ...  \n",
      "961       102626859.0  23.634501 -102.552784  \n",
      "963       471031528.0  20.593684   78.962880  \n",
      "982        55908316.0  55.378051   -3.435973  \n",
      "986               NaN        NaN         NaN  \n",
      "987       270663028.0  37.090240  -95.712891  \n",
      "\n",
      "[195 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#pd.read_csv('C:/Users/srava/Downloads/Global YouTube Statistics.csv')\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(r'C:/Users/srava/Downloads/Global YouTube Statistics.csv', encoding='latin1')\n",
    "\n",
    "filtered_df = df[(df['created_year'] < 2010) & (df['video views'] > 5000000000)]\n",
    "print(filtered_df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Show all YouTubers whose video_views_for_the_last_30_days is missing, but who have more than 1 million subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rank                      Youtuber  subscribers   video views  \\\n",
      "5       6                         Music    119000000  0.000000e+00   \n",
      "12     13                        Gaming     93600000  0.000000e+00   \n",
      "57     58                   BRIGHT SIDE     44500000  1.070853e+10   \n",
      "73     74              Luisito Comunica     40600000  8.670474e+09   \n",
      "102   103                          News     36300000  0.000000e+00   \n",
      "113   114          T-Series Apna Punjab     34600000  2.130632e+10   \n",
      "122   123            Desi Music Factory     33700000  1.018903e+10   \n",
      "149   150                    Luis Fonsi     31400000  1.517676e+10   \n",
      "164   165                   Talking Tom     30200000  1.519933e+10   \n",
      "166   167                 Frost Diamond     30100000  7.277494e+09   \n",
      "180   181            Aditya Music India     28500000  2.585799e+10   \n",
      "190   191            Sandeep Maheshwari     27800000  2.303069e+09   \n",
      "217   218         1MILLION Dance Studio     26100000  7.886440e+09   \n",
      "226   227                 Fede Vigevani     25600000  7.962726e+09   \n",
      "236   237                   Chris Brown     25200000  1.552057e+10   \n",
      "273   274                      FaZe Rug     23700000  7.451792e+09   \n",
      "299   300                   Alan Becker     22900000  5.380074e+09   \n",
      "340   341                          YOLO     21400000  1.573059e+09   \n",
      "348   349       Khan GS Research Centre     21200000  2.073073e+09   \n",
      "360   361             Minecraft - Topic     20900000  0.000000e+00   \n",
      "377   378                   Linkin Park     20400000  1.339700e+10   \n",
      "386   387                Family GamesTV     20200000  7.066711e+09   \n",
      "394   395              Robin Hood Gamer     20100000  1.036685e+10   \n",
      "403   404                    Pentatonix     20000000  6.033296e+09   \n",
      "411   412         Official Pink Panther     19700000  1.095562e+10   \n",
      "440   441                Masha e o Urso     18900000  8.301731e+09   \n",
      "445   446                  Busy Fun Ltd     18800000  7.762077e+09   \n",
      "463   464                     Dhar Mann     18400000  1.128073e+10   \n",
      "468   469         Good Mythical Morning     18300000  8.798045e+09   \n",
      "476   477                   Ajay Sharma     18100000  1.224983e+10   \n",
      "508   509            The Game Theorists     17600000  3.752347e+09   \n",
      "534   535                 Gaby and Alex     17000000  8.229883e+09   \n",
      "543   544                  DeToxoMoroxo     16800000  2.315962e+09   \n",
      "544   545          Doggy Doggy Cartoons     16800000  6.518419e+09   \n",
      "554   555                 Werever2morro     16600000  2.798274e+09   \n",
      "569   570  RCTI - LAYAR DRAMA INDONESIA     16400000  1.347839e+10   \n",
      "592   593                          Live     16100000  0.000000e+00   \n",
      "600   601          La Rosa de Guadalupe     16100000  9.642146e+09   \n",
      "604   605                    Enes Batur     16000000  9.786595e+09   \n",
      "606   607                    ýýýýýýýýýý     15900000  1.845330e+09   \n",
      "629   630                   Super Senya     15500000  5.070971e+09   \n",
      "634   635                     Mr DegrEE     15500000  1.288039e+10   \n",
      "668   669            Hongyu ASMR ï¿½ï¿½     15100000  4.967784e+09   \n",
      "680   681                    TheRichest     15000000  2.730879e+09   \n",
      "687   688                     BigSchool     15000000  9.996133e+09   \n",
      "710   711          Major Lazer Official     14800000  9.383431e+09   \n",
      "735   736                  LEGENDA FUNK     14500000  2.440718e+09   \n",
      "762   763                  Harry Styles     14400000  5.689224e+09   \n",
      "769   770                Rebecca Zamolo     14300000  6.388439e+09   \n",
      "777   778                    Crazy Frog     14200000  7.946322e+09   \n",
      "853   854            Blockbuster Movies     13400000  2.650061e+09   \n",
      "877   878                       Ei Nerd     13200000  3.568392e+09   \n",
      "951   952                       Ja Mill     12500000  1.302818e+09   \n",
      "975   976             Gustavo Parï¿½ï¿½     12400000  2.602614e+09   \n",
      "983   984                      MoniLina     12400000  1.608681e+10   \n",
      "985   986                          TKOR     12400000  3.392023e+09   \n",
      "\n",
      "                 category                         Title  uploads  \\\n",
      "5                     NaN                         Music        0   \n",
      "12                    NaN                        Gaming        0   \n",
      "57          Howto & Style                    brightside        0   \n",
      "73                 Comedy      Luis Arturo Villar Sudek        0   \n",
      "102                   NaN                          News        0   \n",
      "113                 Music         T- Series Apna Punjab        0   \n",
      "122                 Music            Desi music factory        2   \n",
      "149         Entertainment                     luisfonsi        0   \n",
      "164                Comedy                    TalkingTom        2   \n",
      "166                Gaming                  frostdiamond        0   \n",
      "180                 Music                  Aditya Music        0   \n",
      "190        People & Blogs             Sandeepmaheshwari        0   \n",
      "217         Entertainment         1MILLION Dance Studio        0   \n",
      "226         Howto & Style                 Fede Vigevani        0   \n",
      "236                 Music                    ChrisBrown        0   \n",
      "273                Gaming                       FaZeRug        0   \n",
      "299      Film & Animation                   Alan Becker        0   \n",
      "340                Comedy                          YOLO        0   \n",
      "348             Education       KHAN GS RESEARCH CENTRE        1   \n",
      "360                   NaN             Minecraft - Topic        0   \n",
      "377                 Music                    linkinpark        0   \n",
      "386         Entertainment                 FamilyGamesTV        0   \n",
      "394         Entertainment           Homem Aranha player        0   \n",
      "403                 Music                    pentatonix        1   \n",
      "411      Film & Animation           OfficialPinkPanther        1   \n",
      "440                 Shows                Masha e o Urso        0   \n",
      "445                   NaN                  TG MAYANK YT        2   \n",
      "463        People & Blogs              Alejandro Basalo        0   \n",
      "468         Entertainment           Goodmythicalmorning        0   \n",
      "476         Entertainment                   Ajay Sharma        0   \n",
      "508                Gaming              TheGameTheorists        0   \n",
      "534         Entertainment                   gabyandalex        1   \n",
      "543         Entertainment                 de toxomoroxo        1   \n",
      "544         Entertainment          Doggy Doggy Cartoons        0   \n",
      "554         Entertainment                 werever2morro        0   \n",
      "569         Entertainment  RCTI - LAYAR DRAMA INDONESIA        1   \n",
      "592                   NaN                          Live        0   \n",
      "600         Entertainment             larosadeguadalupe        0   \n",
      "604                Gaming                     enesbatur        0   \n",
      "606        People & Blogs                 Kung Fu Padla        0   \n",
      "629         Entertainment                   Super Senya        0   \n",
      "634  Science & Technology                      MrDegree        0   \n",
      "668        People & Blogs           Hongyu ASMR ï¿½ï¿½ï        1   \n",
      "680             Education                    Therichest        0   \n",
      "687                Gaming                    Big School       68   \n",
      "710                 Music            MajorLazerOfficial        0   \n",
      "735                 Music                   LegendaFUNK        0   \n",
      "762        People & Blogs                   harrystyles        0   \n",
      "769                Comedy                 RebeccaZamolo        1   \n",
      "777                 Music                     CrazyFrog        0   \n",
      "853         Entertainment            Blockbuster Movies        0   \n",
      "877         Entertainment                        Einerd        0   \n",
      "951        People & Blogs                        jamill        0   \n",
      "975                Comedy               GustavoParodias        9   \n",
      "983                Comedy                MoniLinaFamily        0   \n",
      "985             Education                          TKoR        0   \n",
      "\n",
      "           Country Abbreviation   channel_type  ...  \\\n",
      "5              NaN          NaN          Music  ...   \n",
      "12             NaN          NaN          Games  ...   \n",
      "57             NaN          NaN            NaN  ...   \n",
      "73          Mexico           MX         Comedy  ...   \n",
      "102            NaN          NaN            NaN  ...   \n",
      "113            NaN          NaN           News  ...   \n",
      "122            NaN          NaN          Music  ...   \n",
      "149            NaN          NaN            NaN  ...   \n",
      "164  United States           US  Entertainment  ...   \n",
      "166            NaN          NaN            NaN  ...   \n",
      "180            NaN          NaN          Music  ...   \n",
      "190      Singapore           SG            NaN  ...   \n",
      "217   Saudi Arabia           SA          Music  ...   \n",
      "226            NaN          NaN            NaN  ...   \n",
      "236            NaN          NaN            NaN  ...   \n",
      "273         Canada           CA          Games  ...   \n",
      "299  United States           US          Games  ...   \n",
      "340        Germany           DE            NaN  ...   \n",
      "348            NaN          NaN         People  ...   \n",
      "360            NaN          NaN          Games  ...   \n",
      "377    Afghanistan           AF          Games  ...   \n",
      "386            NaN          NaN          Games  ...   \n",
      "394            NaN          NaN          Games  ...   \n",
      "403         Canada           CA  Entertainment  ...   \n",
      "411  United States           US          Games  ...   \n",
      "440            NaN          NaN            NaN  ...   \n",
      "445            NaN          NaN            NaN  ...   \n",
      "463            NaN          NaN            NaN  ...   \n",
      "468            NaN          NaN            NaN  ...   \n",
      "476            NaN          NaN            NaN  ...   \n",
      "508      Australia           AU            NaN  ...   \n",
      "534            NaN          NaN         People  ...   \n",
      "543            NaN          NaN          Music  ...   \n",
      "544            NaN          NaN            NaN  ...   \n",
      "554         Mexico           MX          Games  ...   \n",
      "569            NaN          NaN         People  ...   \n",
      "592            NaN          NaN            NaN  ...   \n",
      "600         Mexico           MX          Games  ...   \n",
      "604            NaN          NaN          Games  ...   \n",
      "606         Russia           RU          Games  ...   \n",
      "629            NaN          NaN            NaN  ...   \n",
      "634  United States           US  Entertainment  ...   \n",
      "668            NaN          NaN         People  ...   \n",
      "680  United States           US          Games  ...   \n",
      "687            NaN          NaN           Film  ...   \n",
      "710            NaN          NaN            NaN  ...   \n",
      "735         Brazil           BR          Music  ...   \n",
      "762  United States           US          Games  ...   \n",
      "769  United States           US  Entertainment  ...   \n",
      "777            NaN          NaN          Games  ...   \n",
      "853          India           IN            NaN  ...   \n",
      "877            NaN          NaN          Games  ...   \n",
      "951            NaN          NaN            NaN  ...   \n",
      "975         Brazil           BR         Comedy  ...   \n",
      "983  United States           US         People  ...   \n",
      "985            NaN          NaN         People  ...   \n",
      "\n",
      "     subscribers_for_last_30_days  created_year  created_month  created_date  \\\n",
      "5                             NaN        2013.0            Sep          24.0   \n",
      "12                            NaN        2013.0            Dec          15.0   \n",
      "57                            1.0        2005.0            Nov          18.0   \n",
      "73                            NaN        2010.0            Jun          18.0   \n",
      "102                           NaN        2013.0            Sep           9.0   \n",
      "113                           NaN        2020.0            Jul           9.0   \n",
      "122                           NaN        2018.0            Apr          10.0   \n",
      "149                           NaN        2006.0            Mar          31.0   \n",
      "164                           NaN        2008.0            Jun          27.0   \n",
      "166                           6.0        2006.0            Aug          10.0   \n",
      "180                           NaN        2010.0            Dec          16.0   \n",
      "190                           1.0        2008.0            Jan           2.0   \n",
      "217                           NaN        2019.0            Jul          13.0   \n",
      "226                           2.0        2019.0            Aug           1.0   \n",
      "236                           NaN           NaN            NaN           NaN   \n",
      "273                           1.0        2012.0            Nov          30.0   \n",
      "299                           1.0        2006.0            Mar          21.0   \n",
      "340                           5.0        2013.0            Jun          11.0   \n",
      "348                           NaN        2017.0            Jan           5.0   \n",
      "360                      300000.0        2013.0            Dec          20.0   \n",
      "377                          12.0        2006.0            Nov          28.0   \n",
      "386                           NaN        2012.0            Dec          29.0   \n",
      "394                           NaN        2013.0            Mar          16.0   \n",
      "403                           NaN        2006.0            Mar           9.0   \n",
      "411                           NaN        2011.0            Oct           6.0   \n",
      "440                           2.0        2014.0            Feb          20.0   \n",
      "445                           NaN        2021.0            Dec          21.0   \n",
      "463                           2.0        2007.0            Apr          25.0   \n",
      "468                           NaN           NaN            NaN           NaN   \n",
      "476                           1.0        2009.0            Oct          24.0   \n",
      "508                           NaN           NaN            NaN           NaN   \n",
      "534                           NaN        2008.0            Aug          21.0   \n",
      "543                           NaN        2016.0            Apr          30.0   \n",
      "544                           NaN        2018.0            Nov          11.0   \n",
      "554                           NaN        2010.0            Dec           7.0   \n",
      "569                           NaN        2020.0            Oct          19.0   \n",
      "592                           NaN        2015.0            Jan          13.0   \n",
      "600                           NaN        2008.0            Sep           3.0   \n",
      "604                          11.0        2007.0            Mar           4.0   \n",
      "606                          10.0        2017.0            May          27.0   \n",
      "629                           NaN        2017.0            Jul          27.0   \n",
      "634                          10.0        2016.0            Mar           2.0   \n",
      "668                           NaN        2021.0            Mar          16.0   \n",
      "680                           NaN        2006.0            May          25.0   \n",
      "687                           NaN        2020.0            Dec           2.0   \n",
      "710                           NaN        2013.0            Jun          14.0   \n",
      "735                           NaN           NaN            NaN           NaN   \n",
      "762                           NaN           NaN            NaN           NaN   \n",
      "769                           NaN        2011.0            Aug           4.0   \n",
      "777                           NaN        2005.0            Oct           2.0   \n",
      "853                           NaN        2017.0            Jul           4.0   \n",
      "877                           NaN        2007.0            Nov          19.0   \n",
      "951                           NaN        2006.0            Feb          22.0   \n",
      "975                           NaN        2010.0            Aug          24.0   \n",
      "983                         100.0        2016.0            May          10.0   \n",
      "985                           NaN        2006.0            Aug          16.0   \n",
      "\n",
      "     Gross tertiary education enrollment (%)    Population  Unemployment rate  \\\n",
      "5                                        NaN           NaN                NaN   \n",
      "12                                       NaN           NaN                NaN   \n",
      "57                                       NaN           NaN                NaN   \n",
      "73                                      40.2  1.260140e+08               3.42   \n",
      "102                                      NaN           NaN                NaN   \n",
      "113                                      NaN           NaN                NaN   \n",
      "122                                      NaN           NaN                NaN   \n",
      "149                                      NaN           NaN                NaN   \n",
      "164                                     88.2  3.282395e+08              14.70   \n",
      "166                                      NaN           NaN                NaN   \n",
      "180                                      NaN           NaN                NaN   \n",
      "190                                     84.8  5.703569e+06               4.11   \n",
      "217                                     68.0  3.426853e+07               5.93   \n",
      "226                                      NaN           NaN                NaN   \n",
      "236                                      NaN           NaN                NaN   \n",
      "273                                     68.9  3.699198e+07               5.56   \n",
      "299                                     88.2  3.282395e+08              14.70   \n",
      "340                                     70.2  8.313280e+07               3.04   \n",
      "348                                      NaN           NaN                NaN   \n",
      "360                                      NaN           NaN                NaN   \n",
      "377                                      9.7  3.804175e+07              11.12   \n",
      "386                                      NaN           NaN                NaN   \n",
      "394                                      NaN           NaN                NaN   \n",
      "403                                     68.9  3.699198e+07               5.56   \n",
      "411                                     88.2  3.282395e+08              14.70   \n",
      "440                                      NaN           NaN                NaN   \n",
      "445                                      NaN           NaN                NaN   \n",
      "463                                      NaN           NaN                NaN   \n",
      "468                                      NaN           NaN                NaN   \n",
      "476                                      NaN           NaN                NaN   \n",
      "508                                    113.1  2.576660e+07               5.27   \n",
      "534                                      NaN           NaN                NaN   \n",
      "543                                      NaN           NaN                NaN   \n",
      "544                                      NaN           NaN                NaN   \n",
      "554                                     40.2  1.260140e+08               3.42   \n",
      "569                                      NaN           NaN                NaN   \n",
      "592                                      NaN           NaN                NaN   \n",
      "600                                     40.2  1.260140e+08               3.42   \n",
      "604                                      NaN           NaN                NaN   \n",
      "606                                     81.9  1.443735e+08               4.59   \n",
      "629                                      NaN           NaN                NaN   \n",
      "634                                     88.2  3.282395e+08              14.70   \n",
      "668                                      NaN           NaN                NaN   \n",
      "680                                     88.2  3.282395e+08              14.70   \n",
      "687                                      NaN           NaN                NaN   \n",
      "710                                      NaN           NaN                NaN   \n",
      "735                                     51.3  2.125594e+08              12.08   \n",
      "762                                     88.2  3.282395e+08              14.70   \n",
      "769                                     88.2  3.282395e+08              14.70   \n",
      "777                                      NaN           NaN                NaN   \n",
      "853                                     28.1  1.366418e+09               5.36   \n",
      "877                                      NaN           NaN                NaN   \n",
      "951                                      NaN           NaN                NaN   \n",
      "975                                     51.3  2.125594e+08              12.08   \n",
      "983                                     88.2  3.282395e+08              14.70   \n",
      "985                                      NaN           NaN                NaN   \n",
      "\n",
      "     Urban_population   Latitude   Longitude  \n",
      "5                 NaN        NaN         NaN  \n",
      "12                NaN        NaN         NaN  \n",
      "57                NaN        NaN         NaN  \n",
      "73        102626859.0  23.634501 -102.552784  \n",
      "102               NaN        NaN         NaN  \n",
      "113               NaN        NaN         NaN  \n",
      "122               NaN        NaN         NaN  \n",
      "149               NaN        NaN         NaN  \n",
      "164       270663028.0  37.090240  -95.712891  \n",
      "166               NaN        NaN         NaN  \n",
      "180               NaN        NaN         NaN  \n",
      "190         5703569.0   1.352083  103.819836  \n",
      "217        28807838.0  23.885942   45.079162  \n",
      "226               NaN        NaN         NaN  \n",
      "236               NaN        NaN         NaN  \n",
      "273        30628482.0  56.130366 -106.346771  \n",
      "299       270663028.0  37.090240  -95.712891  \n",
      "340        64324835.0  51.165691   10.451526  \n",
      "348               NaN        NaN         NaN  \n",
      "360               NaN        NaN         NaN  \n",
      "377         9797273.0  33.939110   67.709953  \n",
      "386               NaN        NaN         NaN  \n",
      "394               NaN        NaN         NaN  \n",
      "403        30628482.0  56.130366 -106.346771  \n",
      "411       270663028.0  37.090240  -95.712891  \n",
      "440               NaN        NaN         NaN  \n",
      "445               NaN        NaN         NaN  \n",
      "463               NaN        NaN         NaN  \n",
      "468               NaN        NaN         NaN  \n",
      "476               NaN        NaN         NaN  \n",
      "508        21844756.0 -25.274398  133.775136  \n",
      "534               NaN        NaN         NaN  \n",
      "543               NaN        NaN         NaN  \n",
      "544               NaN        NaN         NaN  \n",
      "554       102626859.0  23.634501 -102.552784  \n",
      "569               NaN        NaN         NaN  \n",
      "592               NaN        NaN         NaN  \n",
      "600       102626859.0  23.634501 -102.552784  \n",
      "604               NaN        NaN         NaN  \n",
      "606       107683889.0  61.524010  105.318756  \n",
      "629               NaN        NaN         NaN  \n",
      "634       270663028.0  37.090240  -95.712891  \n",
      "668               NaN        NaN         NaN  \n",
      "680       270663028.0  37.090240  -95.712891  \n",
      "687               NaN        NaN         NaN  \n",
      "710               NaN        NaN         NaN  \n",
      "735       183241641.0 -14.235004  -51.925280  \n",
      "762       270663028.0  37.090240  -95.712891  \n",
      "769       270663028.0  37.090240  -95.712891  \n",
      "777               NaN        NaN         NaN  \n",
      "853       471031528.0  20.593684   78.962880  \n",
      "877               NaN        NaN         NaN  \n",
      "951               NaN        NaN         NaN  \n",
      "975       183241641.0 -14.235004  -51.925280  \n",
      "983       270663028.0  37.090240  -95.712891  \n",
      "985               NaN        NaN         NaN  \n",
      "\n",
      "[56 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "YouTubers_df = df[\n",
    "    df['video_views_for_the_last_30_days'].isna() &  # Check for missing values\n",
    "    (df['subscribers'] > 1_000_000)]\n",
    "    \n",
    "print(YouTubers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Find all YouTubers from India with more than 100 million subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank   Youtuber  subscribers   video views category      Title  uploads  \\\n",
      "0     1   T-Series    245000000  2.280000e+11    Music   T-Series    20082   \n",
      "4     5  SET India    159000000  1.480000e+11    Shows  SET India   116536   \n",
      "\n",
      "  Country Abbreviation   channel_type  ...  subscribers_for_last_30_days  \\\n",
      "0   India           IN          Music  ...                     2000000.0   \n",
      "4   India           IN  Entertainment  ...                     1000000.0   \n",
      "\n",
      "   created_year  created_month  created_date  \\\n",
      "0        2006.0            Mar          13.0   \n",
      "4        2006.0            Sep          20.0   \n",
      "\n",
      "   Gross tertiary education enrollment (%)    Population  Unemployment rate  \\\n",
      "0                                     28.1  1.366418e+09               5.36   \n",
      "4                                     28.1  1.366418e+09               5.36   \n",
      "\n",
      "   Urban_population   Latitude  Longitude  \n",
      "0       471031528.0  20.593684   78.96288  \n",
      "4       471031528.0  20.593684   78.96288  \n",
      "\n",
      "[2 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "India_df = df[\n",
    "    (df['Country'] == 'India') & \n",
    "    (df['subscribers'] > 100_000_000)  # 100 million\n",
    "]\n",
    "print(India_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Show all YouTubers whose channel type is \"Entertainment\" and who have more than 10 billion views.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rank             Youtuber  subscribers   video views        category  \\\n",
      "2       3              MrBeast    166000000  2.836884e+10   Entertainment   \n",
      "4       5            SET India    159000000  1.480000e+11           Shows   \n",
      "6       7  ýýý Kids Diana Show    112000000  9.324704e+10  People & Blogs   \n",
      "7       8            PewDiePie    111000000  2.905804e+10          Gaming   \n",
      "9      10        Vlad and Niki     98900000  7.718017e+10   Entertainment   \n",
      "..    ...                  ...          ...           ...             ...   \n",
      "845   846       Woody & Kleiny     13500000  1.171722e+10          Comedy   \n",
      "962   963       Family Fitness     12500000  1.038485e+10   Entertainment   \n",
      "963   964            Zee Tamil     12500000  1.155219e+10   Entertainment   \n",
      "964   965       Flowers Comedy     12500000  1.169108e+10   Entertainment   \n",
      "982   983      DisneyChannelUK     12400000  1.260749e+10           Music   \n",
      "\n",
      "                   Title  uploads         Country Abbreviation   channel_type  \\\n",
      "2                MrBeast      741   United States           US  Entertainment   \n",
      "4              SET India   116536           India           IN  Entertainment   \n",
      "6    ýýý Kids Diana Show     1111   United States           US  Entertainment   \n",
      "7              PewDiePie     4716           Japan           JP  Entertainment   \n",
      "9          Vlad and Niki      574   United States           US  Entertainment   \n",
      "..                   ...      ...             ...          ...            ...   \n",
      "845       Woody & Kleiny      975  United Kingdom           GB  Entertainment   \n",
      "962       Family Fitness     1699           India           IN  Entertainment   \n",
      "963            Zee Tamil   102699           India           IN  Entertainment   \n",
      "964       Flowers Comedy    11907           India           IN  Entertainment   \n",
      "982      DisneyChannelUK     4422  United Kingdom           GB  Entertainment   \n",
      "\n",
      "     ...  subscribers_for_last_30_days  created_year  created_month  \\\n",
      "2    ...                     8000000.0        2012.0            Feb   \n",
      "4    ...                     1000000.0        2006.0            Sep   \n",
      "6    ...                           NaN        2015.0            May   \n",
      "7    ...                           NaN        2010.0            Apr   \n",
      "9    ...                      600000.0        2018.0            Apr   \n",
      "..   ...                           ...           ...            ...   \n",
      "845  ...                      400000.0        2013.0            Mar   \n",
      "962  ...                      400000.0        2017.0            Jan   \n",
      "963  ...                      200000.0        2008.0            Aug   \n",
      "964  ...                      100000.0        2015.0            Aug   \n",
      "982  ...                           NaN        2007.0            Dec   \n",
      "\n",
      "     created_date  Gross tertiary education enrollment (%)    Population  \\\n",
      "2            20.0                                     88.2  3.282395e+08   \n",
      "4            20.0                                     28.1  1.366418e+09   \n",
      "6            12.0                                     88.2  3.282395e+08   \n",
      "7            29.0                                     63.2  1.262266e+08   \n",
      "9            23.0                                     88.2  3.282395e+08   \n",
      "..            ...                                      ...           ...   \n",
      "845          30.0                                     60.0  6.683440e+07   \n",
      "962          18.0                                     28.1  1.366418e+09   \n",
      "963          26.0                                     28.1  1.366418e+09   \n",
      "964          19.0                                     28.1  1.366418e+09   \n",
      "982           6.0                                     60.0  6.683440e+07   \n",
      "\n",
      "     Unemployment rate  Urban_population   Latitude   Longitude  \n",
      "2                14.70       270663028.0  37.090240  -95.712891  \n",
      "4                 5.36       471031528.0  20.593684   78.962880  \n",
      "6                14.70       270663028.0  37.090240  -95.712891  \n",
      "7                 2.29       115782416.0  36.204824  138.252924  \n",
      "9                14.70       270663028.0  37.090240  -95.712891  \n",
      "..                 ...               ...        ...         ...  \n",
      "845               3.85        55908316.0  55.378051   -3.435973  \n",
      "962               5.36       471031528.0  20.593684   78.962880  \n",
      "963               5.36       471031528.0  20.593684   78.962880  \n",
      "964               5.36       471031528.0  20.593684   78.962880  \n",
      "982               3.85        55908316.0  55.378051   -3.435973  \n",
      "\n",
      "[103 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "Ent_df = df[\n",
    "    (df['channel_type'] == 'Entertainment') & \n",
    "    (df['video views'] > 10000000000)]\n",
    "print(Ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which category has the most YouTubers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Entertainment            241\n",
      "Music                    202\n",
      "People & Blogs           132\n",
      "Gaming                    94\n",
      "Comedy                    69\n",
      "Film & Animation          46\n",
      "Education                 45\n",
      "Howto & Style             40\n",
      "News & Politics           26\n",
      "Science & Technology      17\n",
      "Shows                     13\n",
      "Sports                    11\n",
      "Pets & Animals             4\n",
      "Trailers                   2\n",
      "Nonprofits & Activism      2\n",
      "Movies                     2\n",
      "Autos & Vehicles           2\n",
      "Travel & Events            1\n",
      "Name: count, dtype: int64\n",
      "Entertainment\n",
      "241\n"
     ]
    }
   ],
   "source": [
    "category_counts = df['category'].value_counts()\n",
    "print(category_counts)\n",
    "most_popular_category = category_counts.idxmax()\n",
    "most_popular_count = category_counts.max()\n",
    "print(most_popular_category)\n",
    "print(most_popular_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top 5 countries by total number of YouTubers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "United States     313\n",
      "India             168\n",
      "Brazil             62\n",
      "United Kingdom     43\n",
      "Mexico             33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "country_counts = df['Country'].value_counts()\n",
    "top_5_countries = country_counts.head(5)\n",
    "print(top_5_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average, minimum, and maximum earnings (both monthly and yearly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lowest Monthly Earnings:\n",
      "Average: 36886.14828140703\n",
      "Minimum: 0.0\n",
      "Maximum: 850900.0\n",
      "\n",
      "Highest Monthly Earnings:\n",
      "Average: 589807.8475879397\n",
      "Minimum: 0.0\n",
      "Maximum: 13600000.0\n",
      "\n",
      "Yearly Earnings (Lowest):\n",
      "Average: 442257.39253266336\n",
      "Minimum: 0.0\n",
      "Maximum: 10200000.0\n",
      "\n",
      "Yearly Earnings (Highest):\n",
      "Average: 7081813.919527639\n",
      "Minimum: 0.0\n",
      "Maximum: 163400000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:/Users/srava/Downloads/Global YouTube Statistics.csv', encoding='latin1')\n",
    "print(\"\\nLowest Monthly Earnings:\")\n",
    "print(\"Average:\", df['lowest_monthly_earnings'].mean())\n",
    "print(\"Minimum:\", df['lowest_monthly_earnings'].min())\n",
    "print(\"Maximum:\", df['lowest_monthly_earnings'].max())\n",
    "\n",
    "\n",
    "print(\"\\nHighest Monthly Earnings:\")\n",
    "print(\"Average:\", df['highest_monthly_earnings'].mean())\n",
    "print(\"Minimum:\", df['highest_monthly_earnings'].min())\n",
    "print(\"Maximum:\", df['highest_monthly_earnings'].max())\n",
    "\n",
    "\n",
    "print(\"\\nYearly Earnings (Lowest):\")\n",
    "print(\"Average:\", df['lowest_yearly_earnings'].mean())\n",
    "print(\"Minimum:\", df['lowest_yearly_earnings'].min())\n",
    "print(\"Maximum:\", df['lowest_yearly_earnings'].max())\n",
    "\n",
    "print(\"\\nYearly Earnings (Highest):\")\n",
    "print(\"Average:\", df['highest_yearly_earnings'].mean())\n",
    "print(\"Minimum:\", df['highest_yearly_earnings'].min())\n",
    "print(\"Maximum:\", df['highest_yearly_earnings'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter YouTubers who belong to countries with an unemployment rate below 5% and have more than 1 million subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YouTubers from countries with unemployment rate below 5% and more than 1 million subscribers:\n",
      "     rank         Youtuber  subscribers   video views              category  \\\n",
      "7       8        PewDiePie    111000000  2.905804e+10                Gaming   \n",
      "8       9      Like Nastya    106000000  9.047906e+10        People & Blogs   \n",
      "13     14        BLACKPINK     89800000  3.214460e+10        People & Blogs   \n",
      "16     17  5-Minute Crafts     80100000  2.623679e+10         Howto & Style   \n",
      "17     18        BANGTANTV     75600000  2.082699e+10                 Music   \n",
      "..    ...              ...          ...           ...                   ...   \n",
      "969   970  Quantum Tech HD     12500000  4.340213e+09  Science & Technology   \n",
      "974   975         Gibby :)     12400000  2.862685e+09        People & Blogs   \n",
      "976   977   SAAIHALILINTAR     12400000  1.113066e+09         Entertainment   \n",
      "982   983  DisneyChannelUK     12400000  1.260749e+10                 Music   \n",
      "992   993            Panda     12300000  2.214684e+09                   NaN   \n",
      "\n",
      "                   Title  uploads         Country Abbreviation   channel_type  \\\n",
      "7              PewDiePie     4716           Japan           JP  Entertainment   \n",
      "8       Like Nastya Vlog      493          Russia           RU         People   \n",
      "13             BLACKPINK      543     South Korea           KR          Music   \n",
      "16   5-Minute Crafts 2.0        1  United Kingdom           GB  Entertainment   \n",
      "17             BANGTANTV     2281     South Korea           KR          Music   \n",
      "..                   ...      ...             ...          ...            ...   \n",
      "969    Mr_Mughall Gaming      223        Pakistan           PK            NaN   \n",
      "974             Gibby :)      226          Mexico           MX         People   \n",
      "976       SAAIHALILINTAR      409       Indonesia           ID  Entertainment   \n",
      "982      DisneyChannelUK     4422  United Kingdom           GB  Entertainment   \n",
      "992          HybridPanda     2452  United Kingdom           GB          Games   \n",
      "\n",
      "     ...  subscribers_for_last_30_days  created_year  created_month  \\\n",
      "7    ...                           NaN        2010.0            Apr   \n",
      "8    ...                      100000.0        2016.0            Jan   \n",
      "13   ...                      700000.0        2016.0            Jun   \n",
      "16   ...                           NaN        2020.0            Jul   \n",
      "17   ...                      400000.0        2012.0            Dec   \n",
      "..   ...                           ...           ...            ...   \n",
      "969  ...                          32.0        2022.0            Apr   \n",
      "974  ...                           NaN        2014.0            Aug   \n",
      "976  ...                           NaN        2012.0            Apr   \n",
      "982  ...                           NaN        2007.0            Dec   \n",
      "992  ...                        1000.0        2006.0            Sep   \n",
      "\n",
      "     created_date  Gross tertiary education enrollment (%)   Population  \\\n",
      "7            29.0                                     63.2  126226568.0   \n",
      "8            14.0                                     81.9  144373535.0   \n",
      "13           29.0                                     94.3   51709098.0   \n",
      "16           27.0                                     60.0   66834405.0   \n",
      "17           17.0                                     94.3   51709098.0   \n",
      "..            ...                                      ...          ...   \n",
      "969          23.0                                      9.0  216565318.0   \n",
      "974          30.0                                     40.2  126014024.0   \n",
      "976          28.0                                     36.3  270203917.0   \n",
      "982           6.0                                     60.0   66834405.0   \n",
      "992          11.0                                     60.0   66834405.0   \n",
      "\n",
      "     Unemployment rate  Urban_population   Latitude   Longitude  \n",
      "7                 2.29       115782416.0  36.204824  138.252924  \n",
      "8                 4.59       107683889.0  61.524010  105.318756  \n",
      "13                4.15        42106719.0  35.907757  127.766922  \n",
      "16                3.85        55908316.0  55.378051   -3.435973  \n",
      "17                4.15        42106719.0  35.907757  127.766922  \n",
      "..                 ...               ...        ...         ...  \n",
      "969               4.45        79927762.0  30.375321   69.345116  \n",
      "974               3.42       102626859.0  23.634501 -102.552784  \n",
      "976               4.69       151509724.0  -0.789275  113.921327  \n",
      "982               3.85        55908316.0  55.378051   -3.435973  \n",
      "992               3.85        55908316.0  55.378051   -3.435973  \n",
      "\n",
      "[210 rows x 28 columns]\n",
      "\n",
      "YouTubers from countries with unemployment rate below 5% and more than 1 million subscribers:\n",
      "     rank         Youtuber  subscribers   video views              category  \\\n",
      "7       8        PewDiePie    111000000  2.905804e+10                Gaming   \n",
      "8       9      Like Nastya    106000000  9.047906e+10        People & Blogs   \n",
      "13     14        BLACKPINK     89800000  3.214460e+10        People & Blogs   \n",
      "16     17  5-Minute Crafts     80100000  2.623679e+10         Howto & Style   \n",
      "17     18        BANGTANTV     75600000  2.082699e+10                 Music   \n",
      "..    ...              ...          ...           ...                   ...   \n",
      "969   970  Quantum Tech HD     12500000  4.340213e+09  Science & Technology   \n",
      "974   975         Gibby :)     12400000  2.862685e+09        People & Blogs   \n",
      "976   977   SAAIHALILINTAR     12400000  1.113066e+09         Entertainment   \n",
      "982   983  DisneyChannelUK     12400000  1.260749e+10                 Music   \n",
      "992   993            Panda     12300000  2.214684e+09                   NaN   \n",
      "\n",
      "                   Title  uploads         Country Abbreviation   channel_type  \\\n",
      "7              PewDiePie     4716           Japan           JP  Entertainment   \n",
      "8       Like Nastya Vlog      493          Russia           RU         People   \n",
      "13             BLACKPINK      543     South Korea           KR          Music   \n",
      "16   5-Minute Crafts 2.0        1  United Kingdom           GB  Entertainment   \n",
      "17             BANGTANTV     2281     South Korea           KR          Music   \n",
      "..                   ...      ...             ...          ...            ...   \n",
      "969    Mr_Mughall Gaming      223        Pakistan           PK            NaN   \n",
      "974             Gibby :)      226          Mexico           MX         People   \n",
      "976       SAAIHALILINTAR      409       Indonesia           ID  Entertainment   \n",
      "982      DisneyChannelUK     4422  United Kingdom           GB  Entertainment   \n",
      "992          HybridPanda     2452  United Kingdom           GB          Games   \n",
      "\n",
      "     ...  subscribers_for_last_30_days  created_year  created_month  \\\n",
      "7    ...                           NaN        2010.0            Apr   \n",
      "8    ...                      100000.0        2016.0            Jan   \n",
      "13   ...                      700000.0        2016.0            Jun   \n",
      "16   ...                           NaN        2020.0            Jul   \n",
      "17   ...                      400000.0        2012.0            Dec   \n",
      "..   ...                           ...           ...            ...   \n",
      "969  ...                          32.0        2022.0            Apr   \n",
      "974  ...                           NaN        2014.0            Aug   \n",
      "976  ...                           NaN        2012.0            Apr   \n",
      "982  ...                           NaN        2007.0            Dec   \n",
      "992  ...                        1000.0        2006.0            Sep   \n",
      "\n",
      "     created_date  Gross tertiary education enrollment (%)   Population  \\\n",
      "7            29.0                                     63.2  126226568.0   \n",
      "8            14.0                                     81.9  144373535.0   \n",
      "13           29.0                                     94.3   51709098.0   \n",
      "16           27.0                                     60.0   66834405.0   \n",
      "17           17.0                                     94.3   51709098.0   \n",
      "..            ...                                      ...          ...   \n",
      "969          23.0                                      9.0  216565318.0   \n",
      "974          30.0                                     40.2  126014024.0   \n",
      "976          28.0                                     36.3  270203917.0   \n",
      "982           6.0                                     60.0   66834405.0   \n",
      "992          11.0                                     60.0   66834405.0   \n",
      "\n",
      "     Unemployment rate  Urban_population   Latitude   Longitude  \n",
      "7                 2.29       115782416.0  36.204824  138.252924  \n",
      "8                 4.59       107683889.0  61.524010  105.318756  \n",
      "13                4.15        42106719.0  35.907757  127.766922  \n",
      "16                3.85        55908316.0  55.378051   -3.435973  \n",
      "17                4.15        42106719.0  35.907757  127.766922  \n",
      "..                 ...               ...        ...         ...  \n",
      "969               4.45        79927762.0  30.375321   69.345116  \n",
      "974               3.42       102626859.0  23.634501 -102.552784  \n",
      "976               4.69       151509724.0  -0.789275  113.921327  \n",
      "982               3.85        55908316.0  55.378051   -3.435973  \n",
      "992               3.85        55908316.0  55.378051   -3.435973  \n",
      "\n",
      "[210 rows x 28 columns]\n",
      "\n",
      "Filtered data saved to 'Filtered_YouTubers_Unemployment_Subscribers.csv'\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[\n",
    "(df['Unemployment rate'] < 5) & \n",
    "(df['subscribers'] > 1_000_000)\n",
    "]\n",
    "print(\"\\nYouTubers from countries with unemployment rate below 5% and more than 1 million subscribers:\")\n",
    "print(filtered_df)\n",
    "print(\"\\nYouTubers from countries with unemployment rate below 5% and more than 1 million subscribers:\")\n",
    "print(filtered_df)\n",
    "\n",
    "filtered_df.to_csv('Filtered_YouTubers_Unemployment_Subscribers.csv', index=False)\n",
    "print(\"\\nFiltered data saved to 'Filtered_YouTubers_Unemployment_Subscribers.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show YouTubers where the difference between lowest_yearly_earnings and highest_monthly_earnings is less than $50,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "Index(['rank', 'Youtuber', 'subscribers', 'video views', 'category', 'Title',\n",
      "       'uploads', 'Country', 'Abbreviation', 'channel_type',\n",
      "       'video_views_rank', 'country_rank', 'channel_type_rank',\n",
      "       'video_views_for_the_last_30_days', 'lowest_monthly_earnings',\n",
      "       'highest_monthly_earnings', 'lowest_yearly_earnings',\n",
      "       'highest_yearly_earnings', 'subscribers_for_last_30_days',\n",
      "       'created_year', 'created_month', 'created_date',\n",
      "       'Gross tertiary education enrollment (%)', 'Population',\n",
      "       'Unemployment rate', 'Urban_population', 'Latitude', 'Longitude'],\n",
      "      dtype='object')\n",
      "\n",
      "YouTubers where the difference between lowest_yearly_earnings and highest_monthly_earnings is less than $50,000:\n",
      "     rank                    Youtuber  subscribers   video views  \\\n",
      "0       1                    T-Series    245000000  2.280000e+11   \n",
      "1       2              YouTube Movies    170000000  0.000000e+00   \n",
      "2       3                     MrBeast    166000000  2.836884e+10   \n",
      "3       4  Cocomelon - Nursery Rhymes    162000000  1.640000e+11   \n",
      "4       5                   SET India    159000000  1.480000e+11   \n",
      "..    ...                         ...          ...           ...   \n",
      "990   991               Natan por Aï¿     12300000  9.029610e+09   \n",
      "991   992    Free Fire India Official     12300000  1.674410e+09   \n",
      "992   993                       Panda     12300000  2.214684e+09   \n",
      "993   994                 RobTopGames     12300000  3.741235e+08   \n",
      "994   995                Make Joke Of     12300000  2.129774e+09   \n",
      "\n",
      "             category                       Title  uploads         Country  \\\n",
      "0               Music                    T-Series    20082           India   \n",
      "1    Film & Animation               youtubemovies        1   United States   \n",
      "2       Entertainment                     MrBeast      741   United States   \n",
      "3           Education  Cocomelon - Nursery Rhymes      966   United States   \n",
      "4               Shows                   SET India   116536           India   \n",
      "..                ...                         ...      ...             ...   \n",
      "990            Sports               Natan por Aï¿     1200          Brazil   \n",
      "991    People & Blogs    Free Fire India Official     1500           India   \n",
      "992               NaN                 HybridPanda     2452  United Kingdom   \n",
      "993            Gaming                 RobTopGames       39          Sweden   \n",
      "994            Comedy                Make Joke Of       62           India   \n",
      "\n",
      "    Abbreviation   channel_type  ...  subscribers_for_last_30_days  \\\n",
      "0             IN          Music  ...                     2000000.0   \n",
      "1             US          Games  ...                           NaN   \n",
      "2             US  Entertainment  ...                     8000000.0   \n",
      "3             US      Education  ...                     1000000.0   \n",
      "4             IN  Entertainment  ...                     1000000.0   \n",
      "..           ...            ...  ...                           ...   \n",
      "990           BR  Entertainment  ...                      700000.0   \n",
      "991           IN          Games  ...                      300000.0   \n",
      "992           GB          Games  ...                        1000.0   \n",
      "993           SE          Games  ...                      100000.0   \n",
      "994           IN         Comedy  ...                      100000.0   \n",
      "\n",
      "     created_year  created_month  created_date  \\\n",
      "0          2006.0            Mar          13.0   \n",
      "1          2006.0            Mar           5.0   \n",
      "2          2012.0            Feb          20.0   \n",
      "3          2006.0            Sep           1.0   \n",
      "4          2006.0            Sep          20.0   \n",
      "..            ...            ...           ...   \n",
      "990        2017.0            Feb          12.0   \n",
      "991        2018.0            Sep          14.0   \n",
      "992        2006.0            Sep          11.0   \n",
      "993        2012.0            May           9.0   \n",
      "994        2017.0            Aug           1.0   \n",
      "\n",
      "     Gross tertiary education enrollment (%)    Population  Unemployment rate  \\\n",
      "0                                       28.1  1.366418e+09               5.36   \n",
      "1                                       88.2  3.282395e+08              14.70   \n",
      "2                                       88.2  3.282395e+08              14.70   \n",
      "3                                       88.2  3.282395e+08              14.70   \n",
      "4                                       28.1  1.366418e+09               5.36   \n",
      "..                                       ...           ...                ...   \n",
      "990                                     51.3  2.125594e+08              12.08   \n",
      "991                                     28.1  1.366418e+09               5.36   \n",
      "992                                     60.0  6.683440e+07               3.85   \n",
      "993                                     67.0  1.028545e+07               6.48   \n",
      "994                                     28.1  1.366418e+09               5.36   \n",
      "\n",
      "     Urban_population   Latitude  Longitude  \n",
      "0         471031528.0  20.593684  78.962880  \n",
      "1         270663028.0  37.090240 -95.712891  \n",
      "2         270663028.0  37.090240 -95.712891  \n",
      "3         270663028.0  37.090240 -95.712891  \n",
      "4         471031528.0  20.593684  78.962880  \n",
      "..                ...        ...        ...  \n",
      "990       183241641.0 -14.235004 -51.925280  \n",
      "991       471031528.0  20.593684  78.962880  \n",
      "992        55908316.0  55.378051  -3.435973  \n",
      "993         9021165.0  60.128161  18.643501  \n",
      "994       471031528.0  20.593684  78.962880  \n",
      "\n",
      "[995 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Column names in the dataset:\")\n",
    "print(df.columns)\n",
    "filtered_df = df[\n",
    "    (df['lowest_yearly_earnings'] - df['highest_monthly_earnings']) < 50000]\n",
    "print(\"\\nYouTubers where the difference between lowest_yearly_earnings and highest_monthly_earnings is less than $50,000:\")\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show rows where created_year is either 2005, 2006, or 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rank                    Youtuber  subscribers   video views  \\\n",
      "0       1                    T-Series    245000000  2.280000e+11   \n",
      "1       2              YouTube Movies    170000000  0.000000e+00   \n",
      "3       4  Cocomelon - Nursery Rhymes    162000000  1.640000e+11   \n",
      "4       5                   SET India    159000000  1.480000e+11   \n",
      "11     12                         WWE     96000000  7.742847e+10   \n",
      "..    ...                         ...          ...           ...   \n",
      "982   983             DisneyChannelUK     12400000  1.260749e+10   \n",
      "985   986                        TKOR     12400000  3.392023e+09   \n",
      "986   987                   ANNA KOVA     12400000  1.395959e+10   \n",
      "987   988               Avril Lavigne     12400000  6.202090e+09   \n",
      "992   993                       Panda     12300000  2.214684e+09   \n",
      "\n",
      "             category                       Title  uploads         Country  \\\n",
      "0               Music                    T-Series    20082           India   \n",
      "1    Film & Animation               youtubemovies        1   United States   \n",
      "3           Education  Cocomelon - Nursery Rhymes      966   United States   \n",
      "4               Shows                   SET India   116536           India   \n",
      "11             Sports                         WWE    70127   United States   \n",
      "..                ...                         ...      ...             ...   \n",
      "982             Music             DisneyChannelUK     4422  United Kingdom   \n",
      "985         Education                        TKoR        0             NaN   \n",
      "986    People & Blogs                    annakova        1             NaN   \n",
      "987             Music               Avril Lavigne      205   United States   \n",
      "992               NaN                 HybridPanda     2452  United Kingdom   \n",
      "\n",
      "    Abbreviation   channel_type  ...  subscribers_for_last_30_days  \\\n",
      "0             IN          Music  ...                     2000000.0   \n",
      "1             US          Games  ...                           NaN   \n",
      "3             US      Education  ...                     1000000.0   \n",
      "4             IN  Entertainment  ...                     1000000.0   \n",
      "11            US         Sports  ...                      600000.0   \n",
      "..           ...            ...  ...                           ...   \n",
      "982           GB  Entertainment  ...                           NaN   \n",
      "985          NaN         People  ...                           NaN   \n",
      "986          NaN           Film  ...                           NaN   \n",
      "987           US          Music  ...                           NaN   \n",
      "992           GB          Games  ...                        1000.0   \n",
      "\n",
      "     created_year  created_month  created_date  \\\n",
      "0          2006.0            Mar          13.0   \n",
      "1          2006.0            Mar           5.0   \n",
      "3          2006.0            Sep           1.0   \n",
      "4          2006.0            Sep          20.0   \n",
      "11         2007.0            May          11.0   \n",
      "..            ...            ...           ...   \n",
      "982        2007.0            Dec           6.0   \n",
      "985        2006.0            Aug          16.0   \n",
      "986        2006.0            Jun          18.0   \n",
      "987        2005.0            Oct           8.0   \n",
      "992        2006.0            Sep          11.0   \n",
      "\n",
      "     Gross tertiary education enrollment (%)    Population  Unemployment rate  \\\n",
      "0                                       28.1  1.366418e+09               5.36   \n",
      "1                                       88.2  3.282395e+08              14.70   \n",
      "3                                       88.2  3.282395e+08              14.70   \n",
      "4                                       28.1  1.366418e+09               5.36   \n",
      "11                                      88.2  3.282395e+08              14.70   \n",
      "..                                       ...           ...                ...   \n",
      "982                                     60.0  6.683440e+07               3.85   \n",
      "985                                      NaN           NaN                NaN   \n",
      "986                                      NaN           NaN                NaN   \n",
      "987                                     88.2  3.282395e+08              14.70   \n",
      "992                                     60.0  6.683440e+07               3.85   \n",
      "\n",
      "     Urban_population   Latitude  Longitude  \n",
      "0         471031528.0  20.593684  78.962880  \n",
      "1         270663028.0  37.090240 -95.712891  \n",
      "3         270663028.0  37.090240 -95.712891  \n",
      "4         471031528.0  20.593684  78.962880  \n",
      "11        270663028.0  37.090240 -95.712891  \n",
      "..                ...        ...        ...  \n",
      "982        55908316.0  55.378051  -3.435973  \n",
      "985               NaN        NaN        NaN  \n",
      "986               NaN        NaN        NaN  \n",
      "987       270663028.0  37.090240 -95.712891  \n",
      "992        55908316.0  55.378051  -3.435973  \n",
      "\n",
      "[164 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:/Users/srava/Downloads/Global YouTube Statistics.csv', encoding='latin1')\n",
    "filtered_data = df[df['created_year'].isin([2005, 2006, 2007])]\n",
    "print(filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column: subscribers_millions by dividing subscribers by 1 million and round to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "   rank                    Youtuber  subscribers   video views  \\\n",
      "0     1                    T-Series    245000000  2.280000e+11   \n",
      "1     2              YouTube Movies    170000000  0.000000e+00   \n",
      "2     3                     MrBeast    166000000  2.836884e+10   \n",
      "3     4  Cocomelon - Nursery Rhymes    162000000  1.640000e+11   \n",
      "4     5                   SET India    159000000  1.480000e+11   \n",
      "\n",
      "           category                       Title  uploads        Country  \\\n",
      "0             Music                    T-Series    20082          India   \n",
      "1  Film & Animation               youtubemovies        1  United States   \n",
      "2     Entertainment                     MrBeast      741  United States   \n",
      "3         Education  Cocomelon - Nursery Rhymes      966  United States   \n",
      "4             Shows                   SET India   116536          India   \n",
      "\n",
      "  Abbreviation   channel_type  ...  subscribers_for_last_30_days  \\\n",
      "0           IN          Music  ...                     2000000.0   \n",
      "1           US          Games  ...                           NaN   \n",
      "2           US  Entertainment  ...                     8000000.0   \n",
      "3           US      Education  ...                     1000000.0   \n",
      "4           IN  Entertainment  ...                     1000000.0   \n",
      "\n",
      "   created_year  created_month  created_date  \\\n",
      "0        2006.0            Mar          13.0   \n",
      "1        2006.0            Mar           5.0   \n",
      "2        2012.0            Feb          20.0   \n",
      "3        2006.0            Sep           1.0   \n",
      "4        2006.0            Sep          20.0   \n",
      "\n",
      "   Gross tertiary education enrollment (%)    Population  Unemployment rate  \\\n",
      "0                                     28.1  1.366418e+09               5.36   \n",
      "1                                     88.2  3.282395e+08              14.70   \n",
      "2                                     88.2  3.282395e+08              14.70   \n",
      "3                                     88.2  3.282395e+08              14.70   \n",
      "4                                     28.1  1.366418e+09               5.36   \n",
      "\n",
      "   Urban_population   Latitude  Longitude  \n",
      "0       471031528.0  20.593684  78.962880  \n",
      "1       270663028.0  37.090240 -95.712891  \n",
      "2       270663028.0  37.090240 -95.712891  \n",
      "3       270663028.0  37.090240 -95.712891  \n",
      "4       471031528.0  20.593684  78.962880  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Data with 'subscribers_millions' column:\n",
      "   subscribers  subscribers_millions\n",
      "0    245000000                 245.0\n",
      "1    170000000                 170.0\n",
      "2    166000000                 166.0\n",
      "3    162000000                 162.0\n",
      "4    159000000                 159.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:/Users/srava/Downloads/Global YouTube Statistics.csv', encoding='latin1')\n",
    "print(\"Original data:\")\n",
    "print(df.head())\n",
    "\n",
    "df['subscribers_millions'] = (df['subscribers'] / 1000000).round(2)\n",
    "\n",
    "print(\"\\nData with 'subscribers_millions' column:\")\n",
    "print(df[['subscribers', 'subscribers_millions']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine created_year, created_month, and created_date into a full datetime column channel_created_at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original date columns:\n",
      "   created_year created_month  created_date\n",
      "0        2006.0           Mar          13.0\n",
      "1        2006.0           Mar           5.0\n",
      "2        2012.0           Feb          20.0\n",
      "3        2006.0           Sep           1.0\n",
      "4        2006.0           Sep          20.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"Mar\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2391\u001b[39m, in \u001b[36mpandas._libs.lib.maybe_convert_numeric\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Unable to parse string \"Mar\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOriginal date columns:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[33m'\u001b[39m\u001b[33mcreated_year\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcreated_month\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcreated_date\u001b[39m\u001b[33m'\u001b[39m]].head())\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mchannel_created_at\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43myear\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcreated_year\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmonth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcreated_month\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mday\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcreated_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mData with \u001b[39m\u001b[33m'\u001b[39m\u001b[33mchannel_created_at\u001b[39m\u001b[33m'\u001b[39m\u001b[33m column:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[33m'\u001b[39m\u001b[33mcreated_year\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcreated_month\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcreated_date\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mchannel_created_at\u001b[39m\u001b[33m'\u001b[39m]].head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\tools\\datetimes.py:1070\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1068\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1069\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m     result = \u001b[43m_assemble_from_unit_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Index):\n\u001b[32m   1072\u001b[39m     cache_array = _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\tools\\datetimes.py:1210\u001b[39m, in \u001b[36m_assemble_from_unit_mappings\u001b[39m\u001b[34m(arg, errors, utc)\u001b[39m\n\u001b[32m   1205\u001b[39m         values = values.astype(\u001b[33m\"\u001b[39m\u001b[33mint64\u001b[39m\u001b[33m\"\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[32m   1208\u001b[39m values = (\n\u001b[32m   1209\u001b[39m     coerce(arg[unit_rev[\u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m]]) * \u001b[32m10000\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1210\u001b[39m     + \u001b[43mcoerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m[\u001b[49m\u001b[43munit_rev\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmonth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m * \u001b[32m100\u001b[39m\n\u001b[32m   1211\u001b[39m     + coerce(arg[unit_rev[\u001b[33m\"\u001b[39m\u001b[33mday\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m   1212\u001b[39m )\n\u001b[32m   1213\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1214\u001b[39m     values = to_datetime(values, \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m, errors=errors, utc=utc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\tools\\datetimes.py:1201\u001b[39m, in \u001b[36m_assemble_from_unit_mappings.<locals>.coerce\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcoerce\u001b[39m(values):\n\u001b[32m   1200\u001b[39m     \u001b[38;5;66;03m# we allow coercion to if errors allows\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     values = \u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1203\u001b[39m     \u001b[38;5;66;03m# prevent overflow in case of int8 or int16\u001b[39;00m\n\u001b[32m   1204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(values.dtype):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\tools\\numeric.py:232\u001b[39m, in \u001b[36mto_numeric\u001b[39m\u001b[34m(arg, errors, downcast, dtype_backend)\u001b[39m\n\u001b[32m    230\u001b[39m coerce_numeric = errors \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     values, new_mask = \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaybe_convert_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_to_masked_nullable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringDtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyarrow_numpy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2433\u001b[39m, in \u001b[36mpandas._libs.lib.maybe_convert_numeric\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Unable to parse string \"Mar\" at position 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:/Users/srava/Downloads/Global YouTube Statistics.csv', encoding='latin1')\n",
    "print(\"Original date columns:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace missing values in channel_type with \"Unknown\" and in Country with \"Unspecified\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"Mar\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2391\u001b[39m, in \u001b[36mpandas._libs.lib.maybe_convert_numeric\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Unable to parse string \"Mar\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#print(df[['created_year', 'created_month', 'created_date']].head())\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mchannel_created_at\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43myear\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcreated_year\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmonth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcreated_month\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mday\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcreated_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#print(\"\\nData with 'channel_created_at' column:\")\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#print(df[['created_year', 'created_month', 'created_date', 'channel_created_at']].head())\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\tools\\datetimes.py:1070\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1068\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1069\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m     result = \u001b[43m_assemble_from_unit_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Index):\n\u001b[32m   1072\u001b[39m     cache_array = _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\tools\\datetimes.py:1210\u001b[39m, in \u001b[36m_assemble_from_unit_mappings\u001b[39m\u001b[34m(arg, errors, utc)\u001b[39m\n\u001b[32m   1205\u001b[39m         values = values.astype(\u001b[33m\"\u001b[39m\u001b[33mint64\u001b[39m\u001b[33m\"\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[32m   1208\u001b[39m values = (\n\u001b[32m   1209\u001b[39m     coerce(arg[unit_rev[\u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m]]) * \u001b[32m10000\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1210\u001b[39m     + \u001b[43mcoerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m[\u001b[49m\u001b[43munit_rev\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmonth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m * \u001b[32m100\u001b[39m\n\u001b[32m   1211\u001b[39m     + coerce(arg[unit_rev[\u001b[33m\"\u001b[39m\u001b[33mday\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m   1212\u001b[39m )\n\u001b[32m   1213\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1214\u001b[39m     values = to_datetime(values, \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m, errors=errors, utc=utc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\tools\\datetimes.py:1201\u001b[39m, in \u001b[36m_assemble_from_unit_mappings.<locals>.coerce\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcoerce\u001b[39m(values):\n\u001b[32m   1200\u001b[39m     \u001b[38;5;66;03m# we allow coercion to if errors allows\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     values = \u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1203\u001b[39m     \u001b[38;5;66;03m# prevent overflow in case of int8 or int16\u001b[39;00m\n\u001b[32m   1204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(values.dtype):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\tools\\numeric.py:232\u001b[39m, in \u001b[36mto_numeric\u001b[39m\u001b[34m(arg, errors, downcast, dtype_backend)\u001b[39m\n\u001b[32m    230\u001b[39m coerce_numeric = errors \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     values, new_mask = \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaybe_convert_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_to_masked_nullable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringDtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyarrow_numpy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2433\u001b[39m, in \u001b[36mpandas._libs.lib.maybe_convert_numeric\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Unable to parse string \"Mar\" at position 0"
     ]
    }
   ],
   "source": [
    "#print(df[['created_year', 'created_month', 'created_date']].head())\n",
    "\n",
    "df['channel_created_at'] = pd.to_datetime(dict(\n",
    "    year=df['created_year'],\n",
    "    month=df['created_month'],\n",
    "    day=df['created_date']\n",
    "))\n",
    "\n",
    "\n",
    "#print(\"\\nData with 'channel_created_at' column:\")\n",
    "#print(df[['created_year', 'created_month', 'created_date', 'channel_created_at']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mar', 'Feb', 'Sep', 'May', 'Apr', 'Jan', 'Dec', 'Jun', 'Aug',\n",
       "       'Jul', 'Oct', 'Nov', nan], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['created_month'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "filtered_df = df[(df['created_month'] == np.nan)]   \n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_value= df['created_month'].unique()[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Youtuber</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>video views</th>\n",
       "      <th>category</th>\n",
       "      <th>Title</th>\n",
       "      <th>uploads</th>\n",
       "      <th>Country</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>channel_type</th>\n",
       "      <th>...</th>\n",
       "      <th>Population</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Urban_population</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>subscribers_display</th>\n",
       "      <th>is_old_channel</th>\n",
       "      <th>subscriber_category</th>\n",
       "      <th>channel_age</th>\n",
       "      <th>upload_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rank, Youtuber, subscribers, video views, category, Title, uploads, Country, Abbreviation, channel_type, video_views_rank, country_rank, channel_type_rank, video_views_for_the_last_30_days, lowest_monthly_earnings, highest_monthly_earnings, lowest_yearly_earnings, highest_yearly_earnings, subscribers_for_last_30_days, created_year, created_month, created_date, Gross tertiary education enrollment (%), Population, Unemployment rate, Urban_population, Latitude, Longitude, subscribers_display, is_old_channel, subscriber_category, channel_age, upload_density]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['created_month'] == nan_value)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before replacement:\n",
      "channel_type     30\n",
      "Country         122\n",
      "dtype: int64\n",
      "\n",
      "Missing values after replacement:\n",
      "channel_type    0\n",
      "Country         0\n",
      "dtype: int64\n",
      "\n",
      "Updated values:\n",
      "    channel_type        Country\n",
      "0          Music          India\n",
      "1          Games  United States\n",
      "2  Entertainment  United States\n",
      "3      Education  United States\n",
      "4  Entertainment          India\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srava\\AppData\\Local\\Temp\\ipykernel_6736\\3021675084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['channel_type'].fillna(\"Unknown\", inplace=True)\n",
      "C:\\Users\\srava\\AppData\\Local\\Temp\\ipykernel_6736\\3021675084.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Country'].fillna(\"Unspecified\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Missing values before replacement:\")\n",
    "print(df[['channel_type', 'Country']].isna().sum())\n",
    "\n",
    "\n",
    "df['channel_type'].fillna(\"Unknown\", inplace=True)\n",
    "df['Country'].fillna(\"Unspecified\", inplace=True)\n",
    "\n",
    "\n",
    "print(\"\\nMissing values after replacement:\")\n",
    "print(df[['channel_type', 'Country']].isna().sum())\n",
    "\n",
    "\n",
    "print(\"\\nUpdated values:\")\n",
    "print(df[['channel_type', 'Country']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the subscribers column to a string with a suffix like \"245M\" for display (e.g., 245000000 → \"245M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Display-friendly subscribers column:\n",
      "   subscribers subscribers_display\n",
      "0    245000000                245M\n",
      "1    170000000                170M\n",
      "2    166000000                166M\n",
      "3    162000000                162M\n",
      "4    159000000                159M\n"
     ]
    }
   ],
   "source": [
    "df['subscribers_display'] = (df['subscribers'] / 1_000_000).round(0).astype(int).astype(str) + \"M\"\n",
    "\n",
    "print(\"\\nDisplay-friendly subscribers column:\")\n",
    "print(df[['subscribers', 'subscribers_display']].head())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace all NaN values in video_views_for_the_last_30_days with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before replacement:\n",
      "0\n",
      "\n",
      "Missing values after replacement:\n",
      "0\n",
      "\n",
      "Updated values:\n",
      "0    2.258000e+09\n",
      "1    1.200000e+01\n",
      "2    1.348000e+09\n",
      "3    1.975000e+09\n",
      "4    1.824000e+09\n",
      "Name: video_views_for_the_last_30_days, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srava\\AppData\\Local\\Temp\\ipykernel_6736\\1867134393.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['video_views_for_the_last_30_days'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 3: Check how many missing values exist (optional)\n",
    "print(\"Missing values before replacement:\")\n",
    "print(df['video_views_for_the_last_30_days'].isna().sum())\n",
    "\n",
    "# Step 4: Replace NaN with 0\n",
    "df['video_views_for_the_last_30_days'].fillna(0, inplace=True)\n",
    "\n",
    "# Step 5: Check again (optional)\n",
    "print(\"\\nMissing values after replacement:\")\n",
    "print(df['video_views_for_the_last_30_days'].isna().sum())\n",
    "\n",
    "# Step 6: Preview the changes\n",
    "print(\"\\nUpdated values:\")\n",
    "print(df['video_views_for_the_last_30_days'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column is_old_channel where value is True if created_year < 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with 'is_old_channel' column:\n",
      "   created_year  is_old_channel\n",
      "0        2006.0            True\n",
      "1        2006.0            True\n",
      "2        2012.0           False\n",
      "3        2006.0            True\n",
      "4        2006.0            True\n"
     ]
    }
   ],
   "source": [
    "df['is_old_channel'] = df['created_year'] < 2010\n",
    "\n",
    "print(\"\\nData with 'is_old_channel' column:\")\n",
    "print(df[['created_year', 'is_old_channel']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin the subscribers column into 5 equal-width bins and label them as \"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binned 'subscribers' into categories:\n",
      "   subscribers subscriber_category\n",
      "0    245000000           Very High\n",
      "1    170000000                High\n",
      "2    166000000                High\n",
      "3    162000000                High\n",
      "4    159000000                High\n"
     ]
    }
   ],
   "source": [
    "labels = [\"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"]\n",
    "\n",
    "df['subscriber_category'] = pd.cut(df['subscribers'], bins=5, labels=labels)\n",
    "\n",
    "print(\"\\nBinned 'subscribers' into categories:\")\n",
    "print(df[['subscribers', 'subscriber_category']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column upload_density = uploads / (current_year - created_year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculated 'upload_density':\n",
      "   uploads  created_year  channel_age  upload_density\n",
      "0    20082        2006.0         19.0     1056.947368\n",
      "1        1        2006.0         19.0        0.052632\n",
      "2      741        2012.0         13.0       57.000000\n",
      "3      966        2006.0         19.0       50.842105\n",
      "4   116536        2006.0         19.0     6133.473684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srava\\AppData\\Local\\Temp\\ipykernel_6736\\1250199567.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['channel_age'].replace(0, 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "current_year = 2025\n",
    "\n",
    "df['channel_age'] = current_year - df['created_year']\n",
    "df['channel_age'].replace(0, 1, inplace=True)  \n",
    "df['upload_density'] = df['uploads'] / df['channel_age']\n",
    "\n",
    "print(\"\\nCalculated 'upload_density':\")\n",
    "print(df[['uploads', 'created_year', 'channel_age', 'upload_density']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values in category using the most frequent value (mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'category' before replacement:\n",
      "46\n",
      "\n",
      "Missing values in 'category' after replacement:\n",
      "0\n",
      "\n",
      "Sample of 'category' values:\n",
      "0               Music\n",
      "1    Film & Animation\n",
      "2       Entertainment\n",
      "3           Education\n",
      "4               Shows\n",
      "Name: category, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srava\\AppData\\Local\\Temp\\ipykernel_6736\\4199061137.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['category'].fillna(most_common_category, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Missing values in 'category' before replacement:\")\n",
    "print(df['category'].isna().sum())\n",
    "\n",
    "most_common_category = df['category'].mode()[0]\n",
    "df['category'].fillna(most_common_category, inplace=True)\n",
    "\n",
    "print(\"\\nMissing values in 'category' after replacement:\")\n",
    "print(df['category'].isna().sum())\n",
    "\n",
    "\n",
    "print(\"\\nSample of 'category' values:\")\n",
    "print(df['category'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column subscriber_growth_rate = subscribers_for_last_30_days / subscribers, in percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subscriber growth rate (%):\n",
      "   subscribers  subscribers_for_last_30_days  subscriber_growth_rate\n",
      "0    245000000                     2000000.0                    0.82\n",
      "1    170000000                           NaN                     NaN\n",
      "2    166000000                     8000000.0                    4.82\n",
      "3    162000000                     1000000.0                    0.62\n",
      "4    159000000                     1000000.0                    0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srava\\AppData\\Local\\Temp\\ipykernel_6736\\3084777011.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['subscribers'].replace(0, pd.NA, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['subscribers'].replace(0, pd.NA, inplace=True)\n",
    "\n",
    "df['subscriber_growth_rate'] = (df['subscribers_for_last_30_days'] / df['subscribers']) * 100\n",
    "\n",
    "df['subscriber_growth_rate'] = df['subscriber_growth_rate'].round(2)\n",
    "\n",
    "print(\"\\nSubscriber growth rate (%):\")\n",
    "print(df[['subscribers', 'subscribers_for_last_30_days', 'subscriber_growth_rate']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flag channels where subscribers_for_last_30_days is more than 10% of total subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Flagged fast-growing channels (more than 10% growth in 30 days):\n",
      "   subscribers  subscribers_for_last_30_days  is_fast_growing\n",
      "0    245000000                     2000000.0            False\n",
      "1    170000000                           NaN            False\n",
      "2    166000000                     8000000.0            False\n",
      "3    162000000                     1000000.0            False\n",
      "4    159000000                     1000000.0            False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srava\\AppData\\Local\\Temp\\ipykernel_6736\\1997422183.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['subscribers'].replace(0, pd.NA, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['subscribers'].replace(0, pd.NA, inplace=True)\n",
    "\n",
    "\n",
    "df['is_fast_growing'] = (df['subscribers_for_last_30_days'] / df['subscribers']) > 0.10\n",
    "\n",
    "\n",
    "print(\"\\nFlagged fast-growing channels (more than 10% growth in 30 days):\")\n",
    "print(df[['subscribers', 'subscribers_for_last_30_days', 'is_fast_growing']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into two new DataFrames: one for channel_type == 'Music' and another for all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Music Channels:\n",
      "    rank           Youtuber  subscribers   video views          category  \\\n",
      "0      1           T-Series    245000000  2.280000e+11             Music   \n",
      "5      6              Music    119000000  0.000000e+00     Entertainment   \n",
      "10    11  Zee Music Company     96700000  5.785629e+10             Music   \n",
      "13    14          BLACKPINK     89800000  3.214460e+10    People & Blogs   \n",
      "14    15          Goldmines     86900000  2.411823e+10  Film & Animation   \n",
      "\n",
      "                Title  uploads      Country Abbreviation channel_type  ...  \\\n",
      "0            T-Series    20082        India           IN        Music  ...   \n",
      "5               Music        0  Unspecified          NaN        Music  ...   \n",
      "10  Zee Music Company     8548        India           IN        Music  ...   \n",
      "13          BLACKPINK      543  South Korea           KR        Music  ...   \n",
      "14          goldmines        1  Unspecified          NaN        Music  ...   \n",
      "\n",
      "    Urban_population   Latitude   Longitude  subscribers_display  \\\n",
      "0        471031528.0  20.593684   78.962880                 245M   \n",
      "5                NaN        NaN         NaN                 119M   \n",
      "10       471031528.0  20.593684   78.962880                  97M   \n",
      "13        42106719.0  35.907757  127.766922                  90M   \n",
      "14               NaN        NaN         NaN                  87M   \n",
      "\n",
      "    is_old_channel  subscriber_category  channel_age  upload_density  \\\n",
      "0             True            Very High         19.0     1056.947368   \n",
      "5            False               Medium         12.0        0.000000   \n",
      "10           False                  Low         11.0      777.090909   \n",
      "13           False                  Low          9.0       60.333333   \n",
      "14            True                  Low         19.0        0.052632   \n",
      "\n",
      "    subscriber_growth_rate  is_fast_growing  \n",
      "0                     0.82            False  \n",
      "5                      NaN            False  \n",
      "10                    1.14            False  \n",
      "13                    0.78            False  \n",
      "14                     NaN            False  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "Other Channels:\n",
      "    rank           Youtuber  subscribers   video views          category  \\\n",
      "0      1           T-Series    245000000  2.280000e+11             Music   \n",
      "5      6              Music    119000000  0.000000e+00     Entertainment   \n",
      "10    11  Zee Music Company     96700000  5.785629e+10             Music   \n",
      "13    14          BLACKPINK     89800000  3.214460e+10    People & Blogs   \n",
      "14    15          Goldmines     86900000  2.411823e+10  Film & Animation   \n",
      "\n",
      "                Title  uploads      Country Abbreviation channel_type  ...  \\\n",
      "0            T-Series    20082        India           IN        Music  ...   \n",
      "5               Music        0  Unspecified          NaN        Music  ...   \n",
      "10  Zee Music Company     8548        India           IN        Music  ...   \n",
      "13          BLACKPINK      543  South Korea           KR        Music  ...   \n",
      "14          goldmines        1  Unspecified          NaN        Music  ...   \n",
      "\n",
      "    Urban_population   Latitude   Longitude  subscribers_display  \\\n",
      "0        471031528.0  20.593684   78.962880                 245M   \n",
      "5                NaN        NaN         NaN                 119M   \n",
      "10       471031528.0  20.593684   78.962880                  97M   \n",
      "13        42106719.0  35.907757  127.766922                  90M   \n",
      "14               NaN        NaN         NaN                  87M   \n",
      "\n",
      "    is_old_channel  subscriber_category  channel_age  upload_density  \\\n",
      "0             True            Very High         19.0     1056.947368   \n",
      "5            False               Medium         12.0        0.000000   \n",
      "10           False                  Low         11.0      777.090909   \n",
      "13           False                  Low          9.0       60.333333   \n",
      "14            True                  Low         19.0        0.052632   \n",
      "\n",
      "    subscriber_growth_rate  is_fast_growing  \n",
      "0                     0.82            False  \n",
      "5                      NaN            False  \n",
      "10                    1.14            False  \n",
      "13                    0.78            False  \n",
      "14                     NaN            False  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "music_df = df[df['channel_type'] == 'Music']\n",
    "others_df = df[df['channel_type'] == 'Music']\n",
    "\n",
    "print(\"\\n Music Channels:\")\n",
    "print(music_df.head())\n",
    "\n",
    "print(\"\\nOther Channels:\")\n",
    "print(others_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a new column continent by mapping countries to continents (e.g., India → Asia, US → North America).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Country to Continent Mapping:\n",
      "         Country      continent\n",
      "0          India           Asia\n",
      "1  United States  North America\n",
      "2  United States  North America\n",
      "3  United States  North America\n",
      "4          India           Asia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srava\\AppData\\Local\\Temp\\ipykernel_6736\\51168225.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['continent'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "country_to_continent = {\n",
    "    'India': 'Asia',\n",
    "    'United States': 'North America'}\n",
    "\n",
    "df['continent'] = df['Country'].map(country_to_continent)\n",
    "\n",
    "df['continent'].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(\"\\nCountry to Continent Mapping:\")\n",
    "print(df[['Country', 'continent']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Urban_population to a percentage of total Population and store it in a column called urban_percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Urban population as % of total:\n",
      "   Urban_population    Population  urban_percent\n",
      "0       471031528.0  1.366418e+09          34.47\n",
      "1       270663028.0  3.282395e+08          82.46\n",
      "2       270663028.0  3.282395e+08          82.46\n",
      "3       270663028.0  3.282395e+08          82.46\n",
      "4       471031528.0  1.366418e+09          34.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srava\\AppData\\Local\\Temp\\ipykernel_6736\\3384997651.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Population'].replace(0, pd.NA, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Population'].replace(0, pd.NA, inplace=True)\n",
    "\n",
    "df['urban_percent'] = (df['Urban_population'] / df['Population']) * 100\n",
    "df['urban_percent'] = df['urban_percent'].round(2)\n",
    "\n",
    "print(\"\\nUrban population as % of total:\")\n",
    "print(df[['Urban_population', 'Population', 'urban_percent']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a channel_age column that shows how many years old a channel is (assuming the current year is 2025)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel age (in years):\n",
      "   created_year  channel_age\n",
      "0        2006.0         19.0\n",
      "1        2006.0         19.0\n",
      "2        2012.0         13.0\n",
      "3        2006.0         19.0\n",
      "4        2006.0         19.0\n"
     ]
    }
   ],
   "source": [
    "current_year = 2025\n",
    "\n",
    "df['channel_age'] = current_year - df['created_year']\n",
    "\n",
    "print(\"\\nChannel age (in years):\")\n",
    "print(df[['created_year', 'channel_age']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by channel_type and calculate the total number of subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total subscribers by channel type:\n",
      "channel_type\n",
      "Animals            58600000\n",
      "Autos              64400000\n",
      "Comedy           1063700000\n",
      "Education        1300200000\n",
      "Entertainment    6922500000\n",
      "Film              964400000\n",
      "Games            2111600000\n",
      "Howto             649100000\n",
      "Music            5771500000\n",
      "News              611700000\n",
      "Nonprofit          55500000\n",
      "People           1953300000\n",
      "Sports            361500000\n",
      "Tech              320800000\n",
      "Unknown           658700000\n",
      "Name: subscribers, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_subscribers_by_type = df.groupby('channel_type')['subscribers'].sum()\n",
    "\n",
    "print(\"\\nTotal subscribers by channel type:\")\n",
    "print(total_subscribers_by_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by Country and find the average video views per channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average video views per channel by country:\n",
      "Country\n",
      "Afghanistan             1.339700e+10\n",
      "Andorra                 2.400038e+09\n",
      "Argentina               1.495503e+10\n",
      "Australia               7.682424e+09\n",
      "Bangladesh              1.212958e+10\n",
      "Barbados                2.247775e+10\n",
      "Brazil                  7.761435e+09\n",
      "Canada                  1.275470e+10\n",
      "Chile                   9.782519e+09\n",
      "China                   2.977742e+09\n",
      "Colombia                1.401798e+10\n",
      "Cuba                    2.293663e+10\n",
      "Ecuador                 2.746231e+09\n",
      "Egypt                   4.912370e+09\n",
      "El Salvador             1.032339e+10\n",
      "Finland                 2.036408e+09\n",
      "France                  6.111528e+09\n",
      "Germany                 9.038708e+09\n",
      "India                   1.357767e+10\n",
      "Indonesia               5.393238e+09\n",
      "Iraq                    8.503826e+09\n",
      "Italy                   9.947449e+09\n",
      "Japan                   1.713640e+10\n",
      "Jordan                  1.769669e+10\n",
      "Kuwait                  4.521574e+09\n",
      "Latvia                  2.091940e+10\n",
      "Malaysia                9.059696e+09\n",
      "Mexico                  6.006665e+09\n",
      "Morocco                 4.315486e+09\n",
      "Netherlands             7.955429e+09\n",
      "Pakistan                1.888224e+10\n",
      "Peru                    1.629801e+09\n",
      "Philippines             1.076067e+10\n",
      "Russia                  1.456227e+10\n",
      "Samoa                   6.637821e+09\n",
      "Saudi Arabia            8.851887e+09\n",
      "Singapore               9.659635e+09\n",
      "South Korea             1.327010e+10\n",
      "Spain                   6.023670e+09\n",
      "Sweden                  5.009226e+09\n",
      "Switzerland             5.529132e+09\n",
      "Thailand                1.468433e+10\n",
      "Turkey                  2.309981e+10\n",
      "Ukraine                 7.308166e+09\n",
      "United Arab Emirates    1.076009e+10\n",
      "United Kingdom          1.001318e+10\n",
      "United States           1.179007e+10\n",
      "Unspecified             9.714364e+09\n",
      "Venezuela               9.673649e+09\n",
      "Vietnam                 8.362771e+09\n",
      "Name: video views, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "average_views_by_country = df.groupby('Country')['video views'].mean().round(2)\n",
    "\n",
    "print(\"\\nAverage video views per channel by country:\")\n",
    "print(average_views_by_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each created_year, compute the number of new channels and average uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New channels and average uploads by created year:\n",
      "              new_channels  average_uploads\n",
      "created_year                               \n",
      "1970.0                   1           744.00\n",
      "2005.0                  23         17437.71\n",
      "2006.0                  87         17249.81\n",
      "2007.0                  48         25536.49\n",
      "2008.0                  45         17359.52\n",
      "2009.0                  51         15355.40\n",
      "2010.0                  48         10836.48\n",
      "2011.0                  82          6547.79\n",
      "2012.0                  68          9145.09\n",
      "2013.0                  73          9474.49\n",
      "2014.0                  97          8217.43\n",
      "2015.0                  72          2685.33\n",
      "2016.0                  76          3592.84\n",
      "2017.0                  63          1426.79\n",
      "2018.0                  45          9279.43\n",
      "2019.0                  31           592.15\n",
      "2020.0                  30          2042.13\n",
      "2021.0                  20           930.43\n",
      "2022.0                   3           167.40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:/Users/srava/Downloads/Global YouTube Statistics.csv', encoding='latin1')\n",
    "yearly_stats = df.groupby('created_year').agg(\n",
    "    new_channels=('channel_type', 'count'),   \n",
    "    average_uploads=('uploads', 'mean')       \n",
    ").round(2) \n",
    "\n",
    "print(\"\\nNew channels and average uploads by created year:\")\n",
    "print(yearly_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the top 3 channel_types by total subscribers_for_last_30_days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 channel types by total subscribers gained in the last 30 days:\n",
      "channel_type\n",
      "Entertainment    92140647.0\n",
      "People           31304887.0\n",
      "Music            28910422.0\n",
      "Name: subscribers_for_last_30_days, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_channel_types = df.groupby('channel_type')['subscribers_for_last_30_days'].sum()\n",
    "\n",
    "\n",
    "top_3_channel_types = top_channel_types.sort_values(ascending=False).head(3)\n",
    "\n",
    "print(\"\\nTop 3 channel types by total subscribers gained in the last 30 days:\")\n",
    "print(top_3_channel_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within each category, find the maximum and minimum highest_monthly_earnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum and minimum highest_monthly_earnings within each category:\n",
      "                       max_highest_monthly_earnings  \\\n",
      "category                                              \n",
      "Autos & Vehicles                          1400000.0   \n",
      "Comedy                                    5000000.0   \n",
      "Education                                 7900000.0   \n",
      "Entertainment                             8100000.0   \n",
      "Film & Animation                          9200000.0   \n",
      "Gaming                                    4300000.0   \n",
      "Howto & Style                             2000000.0   \n",
      "Movies                                     909400.0   \n",
      "Music                                     9000000.0   \n",
      "News & Politics                           1800000.0   \n",
      "Nonprofits & Activism                      598200.0   \n",
      "People & Blogs                            5500000.0   \n",
      "Pets & Animals                            3000000.0   \n",
      "Science & Technology                       670800.0   \n",
      "Shows                                     7300000.0   \n",
      "Sports                                    2900000.0   \n",
      "Trailers                                   723800.0   \n",
      "Travel & Events                            124000.0   \n",
      "\n",
      "                       min_highest_monthly_earnings  \n",
      "category                                             \n",
      "Autos & Vehicles                           772700.0  \n",
      "Comedy                                          0.0  \n",
      "Education                                       0.0  \n",
      "Entertainment                                   0.0  \n",
      "Film & Animation                                0.0  \n",
      "Gaming                                          0.0  \n",
      "Howto & Style                                   0.0  \n",
      "Movies                                          0.0  \n",
      "Music                                           0.0  \n",
      "News & Politics                                 0.0  \n",
      "Nonprofits & Activism                      182600.0  \n",
      "People & Blogs                                  0.0  \n",
      "Pets & Animals                                  0.0  \n",
      "Science & Technology                            0.0  \n",
      "Shows                                           0.0  \n",
      "Sports                                      40900.0  \n",
      "Trailers                                        0.0  \n",
      "Travel & Events                            124000.0  \n"
     ]
    }
   ],
   "source": [
    "earnings_stats = df.groupby('category').agg(\n",
    "    max_highest_monthly_earnings=('highest_monthly_earnings', 'max'),\n",
    "    min_highest_monthly_earnings=('highest_monthly_earnings', 'min')\n",
    ")\n",
    "\n",
    "print(\"\\nMaximum and minimum highest_monthly_earnings within each category:\")\n",
    "print(earnings_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by Country and count how many YouTubers have more than 1 billion views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'video_views'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'video_views'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m billion_views = df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvideo_views\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m > \u001b[32m1_000_000_000\u001b[39m]\n\u001b[32m      3\u001b[39m billion_views_by_country = billion_views.groupby(\u001b[33m'\u001b[39m\u001b[33mCountry\u001b[39m\u001b[33m'\u001b[39m).size()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNumber of YouTubers with more than 1 billion views by country:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'video_views'"
     ]
    }
   ],
   "source": [
    "billion_views = df[df['video_views'] > 1_000_000_000]\n",
    "\n",
    "billion_views_by_country = billion_views.groupby('Country').size()\n",
    "print(\"\\nNumber of YouTubers with more than 1 billion views by country:\")\n",
    "print(billion_views_by_country)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
